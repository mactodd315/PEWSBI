#!/bin/env python

from sbi.inference import SNPE
import torch, numpy, pickle, h5py, argparse, sys, configparser, os
from pycbc.inference.io import (ResultsArgumentParser, results_from_cli,
                                PosteriorFile, loadfile)
import matplotlib.pyplot as plt
from pycbc.strain import insert_strain_option_group_multi_ifo, from_cli_multi_ifos

def details(neuralnet):
    dets = {}
    neuralnet = neuralnet.split('.')[0]
    neuralnet = neuralnet.split('/')[-1]
    l = neuralnet.split('_')
    dets['training_number'] = l[1][2:]
    dets['learning_rate'] = l[2][2:]
    dets['batch_size'] = l[3][2:]
    return dets
def get_samples(net, observations, num_params, args):
    if args.strain_channel:
        samples = numpy.array([numpy.asanyarray(net.sample((args.n_samples,), x=observations))])
    else:
        samples = numpy.ndarray((len(observations), args.n_samples, num_params))
        for i in range(len(observations)):
            samples[i,:,:] = numpy.asanyarray(net.sample((args.n_samples,),
                                                      x=observations[i]))
    
    return samples
def fetch_observation(file, args):
    if args.strain_channel:
        data = file[args.strain_channel]
        delta_t = data.attrs['delta_t']
        if args.observation_start:
            start_index = int((args.observation_start - \
                               data.attrs['start_time'])/delta_t)
        else:
            start_index = 0
        if args.observation_size:
            end_index = int(start_index + args.observation_size)
        else:
            end_index = None
        observations = torch.as_tensor(data[start_index:end_index])
        return observations, None
        
    else:
        observations = torch.as_tensor(file['signals'][:args.observation_num,:])
        true_parameters = {i: file['parameters'][i][:args.observation_num] \
                        for i in args.sample_parameters}
        return observations, true_parameters

if __name__ == "__main__":
    
    ################################################
    parser = argparse.ArgumentParser(
                        prog = "Estimates Posterior: ",
                        description = "Takes in trained neural network \
                              and given observation, and returns an estimated posterior \
                            to the designated output file.",  )

    parser.add_argument("--neural-net", type=str, required=True,
                         help="Path to the trained nerual network (.pickle).")
    parser.add_argument("--output-file", type=str, required=True,
                         help="Path to output file (.hdf)")
    parser.add_argument("--observation-file", type=str,
                        help="Path to observation file (.hdf).")
    parser.add_argument("--IFOs", nargs='+')
    parser.add_argument("--strain-channel")
    parser.add_argument("--observation-start", type=float,
                        help="GPS time to start the slice, defaults to start \
                            time in the dataset attrs.")
    parser.add_argument("--DNRF", default = 1.0)
    parser.add_argument("--whiten", type=str, default=None,
                        help="If path provided, will use that \
                            whitening filter, otherwise generates \
                            a new one from PSD (default).",
                        nargs='?',   const=1)
    parser.add_argument("--observation-size", type=float,
                        help="Size of slice to take from observation, \
                            defaults to entire chunk.")

    parser.add_argument("--sample-parameters", required=True, nargs='+',
                        help="Parameters to make bounds for.")
    parser.add_argument("--observation-num", type=int, default=1)
    parser.add_argument("--n-samples", type=int, default=10000,
                         help="Number of samples to draw from neural network.")
    parser.add_argument("--n-bins", type=int, default=200)
    parser.add_argument("--write-samples", action="store_true", default=False,
                         help="Option to write raw samples drawn from neural network")
    
    parser.add_argument("--write-pycbc-posterior", default=None)
    parser.add_argument("-v", "--verbose", action="store_true", default=False)
    insert_strain_option_group_multi_ifo(parser)
    args = parser.parse_args()
    ###############################################
    # if not os.path.exists(args.output_folder):
    #     os.makedirs(args.output_folder)

    # bounds, parameter_names = get_bounds_from_config(args.config_file)
    
    if args.verbose:
        print("Loading neural network...")
    net = torch.load(args.neural_net, map_location=torch.device('cpu'))

    if args.verbose:  print("Fetching observations...")
    if args.injection_file:
        observations = from_cli_multi_ifos(args, args.IFOs)
        observations = [observations[args.IFOs[0]]] # should change this later
        observations = [each*float(args.DNRF) for each in observations]
        injection_name =list(args.injection_file.values())[0]
        with h5py.File(injection_name, 'r') as f:
            true_parameters = {key: value for key,value in f.attrs.items()}
            

    elif args.observation_file and \
        args.observation_file.split('.')[-1] == 'hdf':
        with h5py.File(args.observation_file, 'r') as f:
            observations, true_parameters = fetch_observation(f, args)
    else:
        raise TypeError
                    
    
    if args.verbose:  print("Sampling...")
    num_params = len(args.sample_parameters) if args.sample_parameters != None else 0
    samples = get_samples(net, observations, num_params, args)

    # getting data
    # nn_params = details(args.neural_net)
    
    
    parameter_names = args.sample_parameters
    
    with h5py.File(args.output_file, 'w') as f:
        pycbc_samples = {parameter_names[j]: samples[0,:,j] for j in range(len(parameter_names))}
        samples = {parameter_names[j]: samples[:,:,j] for j in range(len(parameter_names))} 
        
        for key in samples.keys():
            f[f"samples/{key}"] = samples[key]
        if args.strain_channel == None:
            for key, value in true_parameters.items():
                f[f"true_parameters/{key}"] = value
                # f.attrs['neural_net_data'] = nn_params

    if args.write_pycbc_posterior is not None:
        outtype = PosteriorFile.name
        out = loadfile(args.write_pycbc_posterior, 'w', filetype=outtype) 
        out.write_samples(pycbc_samples)
        out.attrs['static_params'] = []
    


    if args.verbose:  print("All samples written.")
